(docs em pt_BR seguem ap√≥s)
a Karaoke video PLAYER with performance RECORDER for Linux. 
* just a Shell script karaoke: vocal enhanced effects, pitch correction, auto-download YouTube playbacks + final mix/video render 
* based on FFMpeg + LV2 plugins
*AlphaQ - BETAke - now gammaQ v3*

# OPERA SUMMARY

Tonal correction algorithms in general aim to adjust the pitch or pitch of musical notes in an audio recording to ensure that they conform to a particular scale or tonal pattern. These algorithms are often used in audio editing software to correct pitch problems in vocal or instrumental performances.

The mathematical principle underlying tonal correction algorithms involves detecting the fundamental frequencies of musical notes in the audio recording and then applying transformations to adjust these frequencies to match a desired tonal scale. Here is a detailed explanation of the process:


* Detection of Fundamental Frequencies:
The first step is to detect the fundamental frequencies of musical notes in the audio recording. This can be done using spectrum analysis techniques, such as the Fourier Transform, which allows you to decompose the audio signal into its frequency components.

* Correlation with Tonal Scale:
Once the fundamental frequencies are identified, they are correlated with a desired tonal scale. This may involve comparing the detected frequencies with the intervals of the musical scale to determine which notes are being played or sung.

* Pitch Deviation Calculation:
Based on the correlation with the tonal scale, the pitch deviation of each note in relation to the desired scale is calculated. This is done by comparing the detected frequencies to the standard frequencies of the notes in the tonal scale.

* Application of Transformations:
With the pitch deviation determined for each note, transformations are applied to adjust their frequencies. This may involve transposing frequencies up or down to match the correct pitch of the note on the tonal scale.

* Transition Smoothing:
To ensure that transitions between adjusted notes sound natural, interpolation techniques such as linear interpolation or spline interpolation are applied to smooth out frequency changes over time.

* Audio Reprocessing and Synthesis:
After adjusting the frequencies, the audio is reprocessed and synthesized to create a new version of the recording with the tonal corrections applied. This may involve overlaying the adjusted notes over the original recording or synthesizing new sounds based on the applied corrections.

This is a simplified summary of the mathematical principle behind tonal correction algorithms. In practice, these algorithms can be quite complex and incorporate a variety of audio signal processing and mathematical modeling techniques to obtain accurate and natural results.

### this COMPLETE SONNET, in stages:

The Python interface constantly receives updates and new features, but it is the shell script that really does the application's work.
This shell script goes through a series of steps to improve vocal quality in a karaoke recording. Let's look at each of these steps in detail:

## Karaoke Video Download:

Using the yt-dlp tool, the script downloads the karaoke video from the provided URL. The video is then renamed and stored locally.


## Audio and Video Recording:

The script begins by capturing audio and video input from a source, such as a webcam, while the karaoke video plays. This is done by using FFmpeg to record input video and audio simultaneously.


## Audio Processing:

After recording, the voice audio is separated from the video and goes through several processing steps:
First, the audio is noise profiled to identify and remove background noise.
Next, a tonal correction algorithm is applied using the Gareus XC42 and Auburn Sound's Graillon plugin, with volume and equalization adjustments to improve vocal quality.
If the audio has clipping problems, a declipper is used to correct these problems.
Finally, the processed audio is combined with the audio from the original video.

## Final Video Rendering:

After processing the audio, the video is readjusted to synchronize with the processed audio. The delay or advance time is calculated based on the difference in duration between the audio and video recording.
The final rendering combines the original video with the processed audio, applying text to the screen to display the remaining time of the song. The resulting video is then saved.

## MP3 Output File Generation:

In addition to the final video, the script also generates a separate MP3 audio file from the final output file. This allows users to have an audio-only version of the karaoke recording.

## Displaying the Video to the User:

Finally, the final video is played back to the user using FFplay, allowing them to preview the final result of the karaoke recording.
In terms of the quality of the approach, This shell script presents a series of techniques for improving vocal quality, including noise reduction, tonal correction and equalization. However, the effectiveness of these techniques may vary depending on the quality of the original recording and the precision of the algorithms used, being constantly improved, seeking not to exaggerate the resources but rather to build a direct solution, which does not require subtractions from a larger set along the way.

### XC 42:

XC 42 is another tonal correction algorithm, developed by Joshua Reiss and Andrew McLeod. It uses advanced audio signal processing techniques to perform tonal correction on vocal recordings.
The XC 42 is designed to provide accurate and efficient tonal correction, with control over parameters such as the extent of correction and the smoothing of transitions between musical notes.

### Graillon:

Graillon is a machine learning-based tonal correction tool developed by Grzegorz Ptasinski. It uses advanced audio signal processing algorithms and machine learning techniques to perform tonal correction on high-quality audio recordings.
The Graillon is known for its ability to correct pitches precisely and naturally, adapting to the vocal style and nuances of the singer's performance.

# v3.0 - gammaQ.sh


* Receiving Parameters: The script now receives 4 parameters: the karaoke name, the video URL and the beta directory path, now the device v4l2 /dev/video configured in *python launcher*;

* Directory Configuration: Defines directories to store recordings and output files, creating them if they do not exist.

* Colorecho function: Defines a function to print colored messages on the terminal.

* kill_parent_and_children function: Defines a function to kill the parent process and all its children.

* render_display_progress function: Defines a function to display progress using the estimated file size.

* generate_mp3 function: Defines a function to generate an MP3 file from an MP4 file.

* Obtaining Audio Information: Obtains standard system audio and microphone information.

* Updating and Downloading YouTube Video: Updates the YouTube video downloader program (yt-dlp) and downloads the specified YouTube video, saving it to the recordings directory.

* Video Format Check and Conversion: Checks and converts the downloaded video format to ensure compatibility.

* Recording Confirmation Message: Displays a message to confirm karaoke recording.

* Video and Audio Recording: Start recording video and audio from the system's default device.

* Recording Progress Display: Displays a progress bar indicating recording progress.

* Audio Post-Production: Apply filters and audio adjustments, such as dithering, noise reduction and vocal adjustment.

* Final Video Rendering: Combines the post-produced audio with the original video, applying necessary filters and adjustments.

* Generating MP3 File: Generates an MP3 file from the final rendered video.

* Final Video Display: Displays the finished video in the media player.

The script performs several steps to process and produce a complete karaoke from a YouTube video, including downloading, recording, audio post-production, and rendering the final video.

## mastering with SoX, LV2 and FFMpeg complex filter

Before rendering the video that has already been mixed and mastered, some filters are applied through *stand-alone* binaries to the file with the recorded vocals. Over time I noticed that it was more advantageous to divide and conquer, that is, not trying to solve everything in the same FFMpeg pipeline as there would be no compatibility or availability of complex filters to achieve the quality with the desired efficiency.

### Shibata Dithering and Noise Reduction via SoX:

Shibata Dithering is a dithering method used to improve digital audio quality. In the context of scripting, it is applied using SoX (Sound eXchange), a powerful audio processing tool.

The line

```sox "${VOCAL_FILE}" -n trim 0 5 noiseprof "$OUT_DIR"/"$karaoke_name".prof```

creates a noise profile from the first 5 seconds of the previously generated audio file.
Right away,

```sox "${VOCAL_FILE}" "${OUT_VOCAL}" noisered "$OUT_DIR"/"$karaoke_name".prof 0.2 dither -s -f shibata```

applies noise reduction using the created noise profile and applies Shibata Dithering to improve audio quality.

### Gareus XC42 Vocal Tuning Algorithm:

Gareus XC42 is a vocal tuning algorithm developed by Robin Gareus. It is used to adjust and enhance the quality of voices in audio recordings. We use the lv2file tool to efficiently and flexibly apply the filter separately.

The line

```lv2file -i "${OUT_VOCAL}" -o "${VOCAL_FILE}" -P Live http://gareus.org/oss/lv2/fat1```

applies this algorithm to the vocal audio file, generating a new, enhanced audio file.

### Auburn Sound's Graillon Vocal Tuning Algorithm:

Graillon is an audio processing plugin developed by Auburn Sounds used to adjust and modify voices.

The line
```
lv2file -i "${OUT_VOCAL}" -o "${VOCAL_FILE}" -P Younger\ Speech -p p9:1.00 -p p20:2.00 -p p15:0.509 -p p17:1.000 -p p18:1.00 -c 1 :input_38 -c 2:input_39 https://www.auburnsounds.com/products/Graillon.html40733132#in1out2
```
applies the Graillon plugin to the vocal audio file, with different adjustment parameters specified, also using the *lv2file* tool.

* These algorithms are applied to improve vocal audio quality, reduce noise and adjust specific characteristics of the voice to produce a more pleasant and professional end result.
* Each algorithm has its own function and settings that can be adjusted to meet the specific needs of a karaoke recording. A generic balance was sought that could maintain the naturalness of the result but also serve the purpose of improving the original recording.

## post production with FFMpeg

Here the last filters are applied to clean the audio and finally mix with the downloaded playback. Synchronization is guaranteed from recording, where there is a mechanism to only trigger playback for the user when the file is confirmed to be written by FFMpeg. There is also a *diff_ss* variable that guarantees a forced synchronization adjustment in terms of nanoseconds. It is calculated by the difference in value in Unix Epoch nanoseconds at the start of execution of each process, *$epoch_ff* and *$epoch_ffplay*, using the date format *%s*.*%N*

### Audio Configuration:

```
[0:a]volume=volume=0.35, aformat=sample_fmts=fltp:sample_rates=44100:channel_layouts=stereo, aresample=resampler=soxr:osf=s16[playback];
```
This part of the code is responsible for configuring the audio coming from the first input (index [0:a]), the downloaded playback;
```
volume=0.35
```
Sets the audio volume to 35% of the original volume. Absolutely all playbacks from the karaoke communities on You Tube have an unnecessary volume boost that we compensate for in this forced way;

```
aformat=sample_fmts=fltp:sample_rates=44100:channel_layouts=stereo
```

Sets the sampling format (fltp), sample rate (44100 Hz), and channel layout (stereo), for standardization and to mix the two tracks compatible.

```
aresample=resampler=soxr:osf=s16
```

Applies a sample resize using the SoX Resampler (soxr) resampler to convert the audio to a 16-bit sample format.

### Vocal Audio Processing:
```
[1:a] adeclip, compensationdelay, alimiter, speechnorm, acompressor, aecho=0.8:0.8:56:0.33, treble=g=4, aformat=sample_fmts=fltp:sample_rates=44100:channel_layouts=stereo, aresample=resampler=soxr :osf=s16:precision=33[vocals];
```
This part processes the audio coming from the second input (index [1:a]), which is the vocal audio.

* adeclip, compensationdelay, alimiter, speechnorm, acompressor: Apply a series of filters and audio effects, such as distortion removal, delay compensation, limiting, volume normalization and compression.

* aecho=0.8:0.8:56:0.33: Adds a very slight echo to the audio with the specified parameters.
* treble=g=4: Adjusts the treble level of the audio.

```
aformat=sample_fmts=fltp:sample_rates=44100:channel_layouts=stereo
```

Sets the sampling format, sample rate, and channel layout of vocal audio.

```
aresample=resampler=soxr:osf=s16:precision=33
```

Applies sample resizing to vocal audio using SoX Resampler.

### Audio Merging:
```
[playback][vocals] amix=inputs=2:weights=0.45|0.56;
```
Merges the processed playback and vocal audios (defined previously) using the amix function, where inputs=2 indicates that there are two inputs to be merged and weights=0.45|0.56 specifies the weights of each input in the final merge.

### Video Generation:
```
waveform, scale=s=640x360[v1]; gradients=n=7:s=640x360, format=rgba[vscope]; [0:v] scale=s=640x360[v0]; [v1][vscope] xstack=inputs=2, scale=s=640x360[badcoffee]; [v0][badcoffee] vstack=inputs=2, scale=s=640x480;
```
This part sets up the video.

* waveform: Generates an audio waveform. In the final MP4 it is the monochrome frame in the lower left corner.
* gradients: Creates visual gradients. In the final MP4 it is the colored frame to the right of the waveforms.
* [0:v] scale=s=640x360[v0]: Resizes the original video recording of the user singing, to a resolution of 640x360.
* [v1][vscope] xstack=inputs=2: Stacks waveform and gradient videos horizontally, along with playback.
* [v0][badcoffee] vstack=inputs=2: Stacks the resized original video and the xstack result vertically.
* scale=s=640x480: Scales the final video to a resolution of 640x480.

These settings combine audio and video processing to produce a final result that includes audio adjustments, blending of different audio sources, and visual effects applied to the video.

### preview and mp3

* after all this, FFMpeg is invoked again to create an overlay or xstack of the user filmed with the videos with effects and playback. The program then, if everything went well, plays the final file for preview;

* as a courtesy we generated an MP3 of the performance!

* everything is written to the *./outputs* directory
* downloaded playbacks are cached in *./recordings*

# installation

partially implemented

* before running I recommend looking at *install.sh* to evaluate package requirements, python, etc.;
* *BETAKe.py* is the interface itself, there are few python library requirements. This one calls the main shell script *gammaQ.sh*
* I must have already placed most of the requirements in the installer.

# lame DEMOs by Guzpido

https://Xiclet.com.br

## PORTUGUESE DOCS

# RESUMO DA OPERA

Os algoritmos de corre√ß√£o tonal em geral t√™m o objetivo de ajustar a afina√ß√£o ou a altura das notas musicais em uma grava√ß√£o de √°udio para garantir que elas estejam em conformidade com uma determinada escala ou padr√£o tonal. Esses algoritmos s√£o frequentemente usados em softwares de edi√ß√£o de √°udio para corrigir problemas de afina√ß√£o em performances vocais ou instrumentais.

O princ√≠pio matem√°tico subjacente aos algoritmos de corre√ß√£o tonal envolve a detec√ß√£o das frequ√™ncias fundamentais das notas musicais na grava√ß√£o de √°udio e, em seguida, a aplica√ß√£o de transforma√ß√µes para ajustar essas frequ√™ncias para correspond√™ncia com uma escala tonal desejada. Aqui est√° uma explica√ß√£o detalhada do processo:


* Detec√ß√£o de Frequ√™ncias Fundamentais: 
O primeiro passo √© detectar as frequ√™ncias fundamentais das notas musicais na grava√ß√£o de √°udio. Isso pode ser feito usando t√©cnicas de an√°lise de espectro, como a Transformada de Fourier, que permite decompor o sinal de √°udio em suas componentes de frequ√™ncia.

* Correla√ß√£o com Escala Tonal: 
Uma vez que as frequ√™ncias fundamentais s√£o identificadas, elas s√£o correlacionadas com uma escala tonal desejada. Isso pode envolver a compara√ß√£o das frequ√™ncias detectadas com os intervalos da escala musical para determinar quais notas est√£o sendo tocadas ou cantadas.

* C√°lculo do Desvio de Afina√ß√£o: 
Com base na correla√ß√£o com a escala tonal, √© calculado o desvio de afina√ß√£o de cada nota em rela√ß√£o √† escala desejada. Isso √© feito comparando as frequ√™ncias detectadas com as frequ√™ncias padr√£o das notas na escala tonal.

* Aplica√ß√£o de Transforma√ß√µes: 
Com o desvio de afina√ß√£o determinado para cada nota, s√£o aplicadas transforma√ß√µes para ajustar suas frequ√™ncias. Isso pode envolver a transposi√ß√£o das frequ√™ncias para cima ou para baixo para corresponder √† afina√ß√£o correta da nota na escala tonal.

* Suaviza√ß√£o de Transi√ß√µes: 
Para garantir que as transi√ß√µes entre as notas ajustadas soem naturais, s√£o aplicadas t√©cnicas de interpola√ß√£o, como interpola√ß√£o linear ou interpola√ß√£o por splines, para suavizar as mudan√ßas de frequ√™ncia ao longo do tempo.

* Reprocessamento e S√≠ntese de √Åudio: 
Ap√≥s o ajuste das frequ√™ncias, o √°udio √© reprocessado e sintetizado para criar uma nova vers√£o da grava√ß√£o com as corre√ß√µes tonais aplicadas. Isso pode envolver a sobreposi√ß√£o das notas ajustadas sobre a grava√ß√£o original ou a s√≠ntese de novos sons com base nas corre√ß√µes aplicadas.

Este √© um resumo simplificado do princ√≠pio matem√°tico por tr√°s dos algoritmos de corre√ß√£o tonal. Na pr√°tica, esses algoritmos podem ser bastante complexos e incorporar uma variedade de t√©cnicas de processamento de sinais de √°udio e modelagem matem√°tica para obter resultados precisos e naturais.

### este SONETO COMPLETO, por etapas:

A interface python constantemente recebe atualiza√ß√µes e novas features, mas √© o shell script que realmente faz o trabalho da aplica√ß√£o. 
Este script shell aborda uma s√©rie de etapas para melhorar a qualidade vocal em uma grava√ß√£o de karaok√™. Vamos analisar cada uma dessas etapas em detalhes:

## Download do V√≠deo de Karaok√™:

Utilizando a ferramenta yt-dlp, o script faz o download do v√≠deo de karaok√™ da URL fornecida. O v√≠deo √© ent√£o renomeado e armazenado localmente.


## Grava√ß√£o de √Åudio e V√≠deo:

O script come√ßa capturando a entrada de √°udio e v√≠deo de uma fonte, como uma webcam, enquanto o v√≠deo de karaok√™ √© reproduzido. Isso √© feito usando o FFmpeg para gravar a entrada de v√≠deo e √°udio simultaneamente.


## Processamento de √Åudio:

Ap√≥s a grava√ß√£o, o √°udio da voz √© separado do v√≠deo e passa por v√°rias etapas de processamento:
Primeiramente, o √°udio √© submetido a um perfil de ru√≠do para identificar e remover o ru√≠do de fundo.
Em seguida, √© aplicado um algoritmo de corre√ß√£o tonal usando o plugin Gareus XC42 e Auburn Sound's Graillon, com ajustes de volume e equaliza√ß√£o para melhorar a qualidade vocal.
Se o √°udio apresentar problemas de clipping, √© utilizado um declipper para corrigir esses problemas.
Finalmente, o √°udio processado √© combinado com o √°udio do v√≠deo original.

## Renderiza√ß√£o do V√≠deo Final:

Ap√≥s o processamento do √°udio, o v√≠deo √© reajustado para sincronizar com o √°udio tratado. O tempo de atraso ou adiantamento √© calculado com base na diferen√ßa de dura√ß√£o entre a grava√ß√£o do √°udio e do v√≠deo.
A renderiza√ß√£o final combina o v√≠deo original com o √°udio tratado, aplicando texto na tela para exibir o tempo restante da m√∫sica. O v√≠deo resultante √© ent√£o salvo.

## Gera√ß√£o de Arquivo de Sa√≠da MP3:

Al√©m do v√≠deo final, o script tamb√©m gera um arquivo de √°udio MP3 separado a partir do arquivo de sa√≠da final. Isso permite que os usu√°rios tenham uma vers√£o apenas de √°udio da grava√ß√£o de karaok√™.

## Exibi√ß√£o do V√≠deo para o Usu√°rio:

Por fim, o v√≠deo final √© reproduzido para o usu√°rio usando o FFplay, permitindo que eles visualizem o resultado final da grava√ß√£o de karaok√™.
Em termos de qualidade da abordagem, este script shell apresenta uma s√©rie de t√©cnicas para melhorar a qualidade vocal, incluindo redu√ß√£o de ru√≠do, corre√ß√£o tonal e equaliza√ß√£o. No entanto, a efic√°cia dessas t√©cnicas pode variar dependendo da qualidade da grava√ß√£o original e da precis√£o dos algoritmos utilizados, estando em constante aperfei√ßoamento, buscando n√£o exagerar nos recursos mas sim construir uma solu√ß√£o direta, que n√£o obrigue subtra√ß√µes de um conjunto maior no percurso.

### XC 42:

O XC 42 √© outro algoritmo de corre√ß√£o tonal, desenvolvido por Joshua Reiss e Andrew McLeod. Ele usa t√©cnicas avan√ßadas de processamento de sinais de √°udio para realizar corre√ß√£o tonal em grava√ß√µes vocais.
O XC 42 √© projetado para oferecer corre√ß√£o tonal precisa e eficiente, com controle sobre par√¢metros como a extens√£o de corre√ß√£o e a suaviza√ß√£o de transi√ß√µes entre notas musicais.

### Graillon:

O Graillon √© uma ferramenta de corre√ß√£o tonal baseada em aprendizado de m√°quina, desenvolvida por Grzegorz Ptasinski. Ele usa algoritmos avan√ßados de processamento de sinais de √°udio e t√©cnicas de aprendizado de m√°quina para realizar corre√ß√£o tonal em grava√ß√µes de √°udio de alta qualidade.
O Graillon √© conhecido por sua capacidade de corrigir afina√ß√µes de forma precisa e natural, adaptando-se ao estilo vocal e √†s nuances da performance do cantor.

# v3.0 - gammaQ.sh


* Recebendo Par√¢metros: O script recebe agora 4 par√¢metros: o nome do karaok√™, a URL do v√≠deo e o caminho do diret√≥rio beta, agora o dispositivo v4l2 /dev/video configurado no *python launcher*;

* Configura√ß√£o de Diret√≥rios: Define diret√≥rios para armazenar grava√ß√µes e arquivos de sa√≠da, criando-os se n√£o existirem.

* Fun√ß√£o colorecho: Define uma fun√ß√£o para imprimir mensagens coloridas no terminal.

* Fun√ß√£o kill_parent_and_children: Define uma fun√ß√£o para encerrar o processo pai e todos os seus filhos.

* Fun√ß√£o render_display_progress: Define uma fun√ß√£o para exibir o progresso usando o tamanho estimado do arquivo.

* Fun√ß√£o generate_mp3: Define uma fun√ß√£o para gerar um arquivo MP3 a partir de um arquivo MP4.

* Obtendo Informa√ß√µes de √Åudio: Obt√©m informa√ß√µes padr√£o de √°udio e microfone do sistema.

* Atualizando e Baixando V√≠deo do YouTube: Atualiza o programa de download de v√≠deos do YouTube (yt-dlp) e baixa o v√≠deo do YouTube especificado, salvando-o no diret√≥rio de grava√ß√µes.

* Verifica√ß√£o e Convers√£o de Formato do V√≠deo: Verifica e converte o formato do v√≠deo baixado para garantir compatibilidade.

* Mensagem de Confirma√ß√£o de Grava√ß√£o: Exibe uma mensagem para confirmar a grava√ß√£o do karaok√™.

* Grava√ß√£o de V√≠deo e √Åudio: Inicia a grava√ß√£o de v√≠deo e √°udio a partir do dispositivo padr√£o do sistema.

* Exibi√ß√£o do Progresso da Grava√ß√£o: Exibe uma barra de progresso indicando o progresso da grava√ß√£o.

* P√≥s-Produ√ß√£o de √Åudio: Aplica filtros e ajustes de √°udio, como dithering, redu√ß√£o de ru√≠do e ajuste vocal.

* Renderiza√ß√£o do V√≠deo Final: Combina o √°udio p√≥s-produzido com o v√≠deo original, aplicando filtros e ajustes necess√°rios.

* Gerando Arquivo MP3: Gera um arquivo MP3 a partir do v√≠deo final renderizado.

* Exibi√ß√£o do V√≠deo Final: Exibe o v√≠deo finalizado no player de m√≠dia.

O script realiza v√°rias etapas para processar e produzir um karaok√™ completo a partir de um v√≠deo do YouTube, incluindo download, grava√ß√£o, p√≥s-produ√ß√£o de √°udio e renderiza√ß√£o do v√≠deo final.

## masteriza√ß√£o com SoX, LV2 e FFMpeg complex filter

Antes de renderizar o v√≠deo que j√° mixa e masteriza, alguns filtros s√£o aplicados por meio de bin√°rios *stand-alone* no arquivo com os vocais gravados. Com o tempo notei que era mais vantajoso dividir para conquistar, ou seja, n√£o tentar resolver tudo na mesma pipeline de FFMpeg pois n√£o haveria compatibilidade ou disponibilidade de filtros complexos para alcan√ßar a qualidade com a efici√™ncia desejada.

### Shibata Dithering e Redu√ß√£o de Ru√≠do via SoX:

O Shibata Dithering √© um m√©todo de dithering usado para melhorar a qualidade de √°udio digital. No contexto do script, √© aplicado usando o SoX (Sound eXchange), uma poderosa ferramenta de processamento de √°udio.
A linha 
```sox "${VOCAL_FILE}" -n trim 0 5 noiseprof "$OUT_DIR"/"$karaoke_name".prof``` 
cria um perfil de ru√≠do a partir dos primeiros 5 segundos do arquivo de √°udio gerado anteriormente.
Em seguida, 
```
sox "${VOCAL_FILE}" "${OUT_VOCAL}" noisered "$OUT_DIR"/"$karaoke_name".prof 0.2 dither -s -f shibata 
```
aplica a redu√ß√£o de ru√≠do usando o perfil de ru√≠do criado e aplica o Shibata Dithering para melhorar a qualidade do √°udio.

### Algoritmo de Ajuste Vocal Gareus XC42:

O Gareus XC42 √© um algoritmo de ajuste vocal desenvolvido por Robin Gareus. Ele √© usado para ajustar e aprimorar a qualidade das vozes nas grava√ß√µes de √°udio. Usamos a ferramenta lv2file para aplicar com efici√™ncia e flexibilidade o filtro, separadamente.

A linha 
```
lv2file -i "${OUT_VOCAL}" -o "${VOCAL_FILE}" -P Live http://gareus.org/oss/lv2/fat1 
```
aplica esse algoritmo ao arquivo de √°udio vocal, gerando um novo arquivo de √°udio aprimorado.

### Algoritmo de Ajuste Vocal Auburn Sound's Graillon:

O Graillon √© um plugin de processamento de √°udio desenvolvido pela Auburn Sounds, usado para ajustar e modificar vozes.

A linha 
```
lv2file -i "${OUT_VOCAL}" -o "${VOCAL_FILE}" -P Younger\ Speech -p p9:1.00 -p p20:2.00 -p p15:0.509 -p p17:1.000 -p p18:1.00 -c 1:input_38 -c 2:input_39 https://www.auburnsounds.com/products/Graillon.html40733132#in1out2 
```
aplica o plugin Graillon ao arquivo de √°udio vocal, com diferentes par√¢metros de ajuste especificados, tamb√©m utilizando a ferramenta *lv2file*.

* Esses algoritmos s√£o aplicados para melhorar a qualidade do √°udio vocal, reduzir o ru√≠do e ajustar caracter√≠sticas espec√≠ficas da voz para produzir um resultado final mais agrad√°vel e profissional.
* Cada algoritmo tem sua pr√≥pria fun√ß√£o e configura√ß√µes que podem ser ajustadas para atender √†s necessidades espec√≠ficas de uma grava√ß√£o de karaok√™. Buscou-se um equilibrio gen√©rico que pudesse manter a naturalidade do resultado mas tamb√©m atendesse o prop√≥sito de aperfei√ßoar a grava√ß√£o original.

## p√≥s produ√ß√£o com FFMpeg

Aqui se aplicam os √∫ltimos filtros para limpeza do audio e finalmente a mixagem com o playback baixado. A sincronia √© garantida desde a grava√ß√£o, onde existe um mecanismo de somente disparar o playback para o usu√°rio quando o arquivo est√° confirmadamente sendo escrito pelo FFMpeg. Existe ainda uma vari√°vel *diff_ss* que garante em termos de nanosegundos um ajuste for√ßado de sincronia. Ela √© calculada pela diferen√ßa de valor em nanosegundos do Unix Epoch do in√≠cio de execu√ß√£o de cada processo, *$epoch_ff* e *$epoch_ffplay*, usando o formato de data *%s*.*%N*

### Configura√ß√£o do √Åudio:

```
[0:a]volume=volume=0.35, aformat=sample_fmts=fltp:sample_rates=44100:channel_layouts=stereo, aresample=resampler=soxr:osf=s16[playback];
```
Esta parte do c√≥digo √© respons√°vel por configurar o √°udio proveniente da primeira entrada (√≠ndice [0:a]), o playback baixado;
```
volume=0.35
```
Define o volume do √°udio para 35% do volume original. Absolutamente todos os playbacks das comunidades de karaoke no You Tube tem um boost desnecess√°rio de volume que compensamos dessa forma for√ßada;

```
aformat=sample_fmts=fltp:sample_rates=44100:channel_layouts=stereo
```

Define o formato de amostragem (fltp), a taxa de amostragem (44100 Hz) e o layout de canal (est√©reo), para padroniza√ß√£o e para mixar as duas faixas de forma compat√≠vel.

```
aresample=resampler=soxr:osf=s16 
```

Aplica um redimensionamento de amostra usando o resampler SoX Resampler (soxr) para converter o √°udio para um formato de amostra de 16 bits.

### Processamento do √Åudio Vocal:
```
[1:a] adeclip, compensationdelay, alimiter, speechnorm, acompressor, aecho=0.8:0.8:56:0.33, treble=g=4, aformat=sample_fmts=fltp:sample_rates=44100:channel_layouts=stereo, aresample=resampler=soxr:osf=s16:precision=33[vocals];
```
Esta parte processa o √°udio proveniente da segunda entrada (√≠ndice [1:a]), que √© o √°udio vocal.

* adeclip, compensationdelay, alimiter, speechnorm, acompressor: Aplicam uma s√©rie de filtros e efeitos de √°udio, como remo√ß√£o de distor√ß√£o, atraso de compensa√ß√£o, limita√ß√£o, normaliza√ß√£o de volume e compress√£o.

* aecho=0.8:0.8:56:0.33: Adiciona um eco bem leve ao √°udio com os par√¢metros especificados.
* treble=g=4: Ajusta o n√≠vel de agudos do √°udio.

```
aformat=sample_fmts=fltp:sample_rates=44100:channel_layouts=stereo
```

Define o formato de amostragem, taxa de amostragem e layout de canal do √°udio vocal.

```
aresample=resampler=soxr:osf=s16:precision=33
```

Aplica o redimensionamento de amostra ao √°udio vocal usando o SoX Resampler.

### Mesclagem de √Åudio:
```
[playback][vocals] amix=inputs=2:weights=0.45|0.56;
```
Mescla os √°udios processados do playback e dos vocais (definidos anteriormente) usando a fun√ß√£o amix, onde inputs=2 indica que h√° duas entradas a serem mescladas e weights=0.45|0.56 especifica os pesos de cada entrada na mesclagem final.

### Gera√ß√£o de V√≠deo:
```
waveform, scale=s=640x360[v1]; gradients=n=7:s=640x360, format=rgba[vscope]; [0:v] scale=s=640x360[v0]; [v1][vscope] xstack=inputs=2, scale=s=640x360[badcoffee]; [v0][badcoffee] vstack=inputs=2, scale=s=640x480;
```
Esta parte configura o v√≠deo.

* waveform: Gera uma forma de onda do √°udio. No MP4 final ele √© o quadro monocrom√°tico do canto inferior esquerdo.
* gradients: Cria gradientes visuais. No MP4 final ele √© o quadro colorido ao lado direito dos waveforms.
* [0:v] scale=s=640x360[v0]: Redimensiona o v√≠deo original da grava√ß√£o do usu√°rio cantando, para uma resolu√ß√£o de 640x360.
* [v1][vscope] xstack=inputs=2: Empilha os v√≠deos da forma de onda e dos gradientes horizontalmente, junto com o playback.
* [v0][badcoffee] vstack=inputs=2: Empilha o v√≠deo original redimensionado e o resultado do xstack verticalmente.
* scale=s=640x480: Redimensiona o v√≠deo final para uma resolu√ß√£o de 640x480.

Essas configura√ß√µes combinam processamento de √°udio e v√≠deo para produzir um resultado final que inclui ajustes de √°udio, mesclagem de diferentes fontes de √°udio e efeitos visuais aplicados ao v√≠deo.

### preview e mp3

* ap√≥s tudo isso, novamente se invoca o FFMpeg para criar um overlay ou xstack do usu√°rio filmado com os v√≠deos com efeitos e o playback. O programa ent√£o se tudo deu certo, toca o arquivo final para preview;

* por cortesia geramos uma MP3 da performance!

* tudo √© gravado no diret√≥rio *./outputs*
* os playbacks baixados ficam em cache em *./recordings*

# instala√ß√£o 

parcialmente implementada

* antes de rodar recomendo olhar o *instalar.sh* para avaliar os requisitos de pacotes, python, etc;
* *BETAKe.py* √© a interface em si, s√£o poucos requisitos de biblioteca python. Este que chama o script shell principal *gammaQ.sh*
* a maioria dos requisitos j√° devo ter colocado no instalador.

# DEMOs fuleiros by Guzpido

https://Xiclet.com.br

